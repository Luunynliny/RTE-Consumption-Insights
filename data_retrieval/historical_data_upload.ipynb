{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_20896\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload historical data (that we downloaded with their corresponding python script) on RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "file_path_production_type = 'data/production_type.csv'\n",
    "file_path_power_consumption = 'data/power_consumption.csv'\n",
    "file_path_weekly_forecast = 'data/weekly_forecast.csv'\n",
    "\n",
    "\n",
    "# Define the data types for each column\n",
    "dtype_production_type = {'production_type': 'category'}  \n",
    "dtype_power_consumption = {\"status\": 'category'}\n",
    "# dtype_weekly_forecast = {'column3': 'category'}\n",
    "\n",
    "# Load the dataframes with specified data types\n",
    "df_production_type = pd.read_csv(file_path_production_type, parse_dates=['start_date','end_date','updated_date'])\n",
    "df_power_consumption = pd.read_csv(file_path_power_consumption, dtype=dtype_power_consumption, parse_dates=['start_date','end_date','updated_date'])\n",
    "df_weekly_forecast = pd.read_csv(file_path_weekly_forecast, parse_dates=['start_date','end_date','updated_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['start_date', 'end_date', 'updated_date', 'production_value',\n",
       "       'production_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_production_type.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# # Create SQLAlchemy engine to connect to MySQL Database\n",
    "# engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "#                        .format(user=\"admin\",\n",
    "#                                pw=\"admin2024\",\n",
    "#                                host=\"mysql-database.c9cwko0aaypr.eu-central-1.rds.amazonaws.com\",\n",
    "#                                db=\"rte\"))\n",
    "\n",
    "# # Convert and upload the DataFrame to MySQL\n",
    "# df_production_type.to_sql('production_type_5years', con = engine, if_exists = 'append', chunksize = 1000)\n",
    "# df_power_consumption.to_sql('power_consumption_5years', con = engine, if_exists = 'append', chunksize = 1000)\n",
    "# df_weekly_forecast.to_sql('weekly_forecast_5years', con = engine, if_exists = 'append', chunksize = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join theses 3 tables into one and upload onto RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['start_date', 'end_date', 'updated_date', 'production_value',\n",
      "       'production_type'],\n",
      "      dtype='object')\n",
      "Index(['start_date', 'end_date', 'consolidated_power_consumption_value',\n",
      "       'updated_date', 'status'],\n",
      "      dtype='object')\n",
      "Index(['start_date', 'end_date', 'forecast_value', 'updated_date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_production_type.columns)\n",
    "print(df_power_consumption.columns)\n",
    "print(df_weekly_forecast.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production_type.rename(columns={'updated_date': 'production_updated_date'}, inplace=True)\n",
    "df_power_consumption.rename(columns={'updated_date': 'consumption_updated_date'}, inplace=True)\n",
    "df_weekly_forecast.rename(columns={'updated_date': 'forecast_updated_date'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the same 30 minutes intervall for their values\n",
    "merged_df = df_power_consumption.merge(df_weekly_forecast, on=['start_date', 'end_date'], how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448294"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # consumption + forecast\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# # Create SQLAlchemy engine to connect to MySQL Database\n",
    "# engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "#                        .format(user=\"admin\",\n",
    "#                                pw=\"admin2024\",\n",
    "#                                host=\"mysql-database.c9cwko0aaypr.eu-central-1.rds.amazonaws.com\",\n",
    "#                                db=\"rte\"))\n",
    "\n",
    "# # Convert and upload the DataFrame to MySQL\n",
    "# merged_df.to_sql('consumption_and_forecast_5years', con = engine, if_exists = 'append', chunksize = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join production but it has time deltas of 1 hour instead of 2 lines for each 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production_type.rename(columns={'end_date': 'production_end_date'}, inplace=True)\n",
    "# df_production_type = df_production_type.rename(columns={'production_start_date': 'start_date'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on start_date as it is not the same interval (30 mins vs 1 hour)\n",
    "merged_df_2 = merged_df.merge(df_production_type, on='start_date', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2910916"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create SQLAlchemy engine to connect to MySQL Database\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                       .format(user=\"admin\",\n",
    "                               pw=\"admin2024\",\n",
    "                               host=\"mysql-database.c9cwko0aaypr.eu-central-1.rds.amazonaws.com\",\n",
    "                               db=\"rte\"))\n",
    "\n",
    "# Convert and upload the DataFrame to MySQL\n",
    "merged_df_2.to_sql('production_consumption_and_forecast_5years', con = engine, if_exists = 'append', chunksize = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
